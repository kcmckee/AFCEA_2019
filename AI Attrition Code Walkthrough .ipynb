{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Killian McKee "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview ##\n",
    "\n",
    "This code steps through several machine learning algorithms and a deep neural net to demonstrate how artificial intelligence can be used to improve employee retention. Using past data on employees, we can treat retention as a classificiation problem i.e. is this employee a flight risk or not? Given this information key decision leaders can act to preserve their talent accordingly. For this simple walkthrough we will be using IBM's attrition [dataset](https://www.ibm.com/communities/analytics/watson-analytics-blog/hr-employee-attrition/). We will be walking through 5 powerful, widely used classification methods: extreme gradient boosting, logistic regression, a random forest, support vector machines, and a basic deep neural net. To keep this section relatively compact, we use a a pre-encoded version of the data for our first 4 algorithms, but the full data preparation pipeline is included in the neural net section. Ultimately, we achieve a peak accuracy of about 89.1% using logistic regression, which is acceptable considering the small dataset size and the serious class imbalance (83% of the data falls into the 'did not commit attrition' class). In a large scale implementation, more data would likely be avaialble to improve results. Additionally, there is room for improvement in hyperparameter tuning and training time. The purpose of this guide is not to maximize accuracy, but to demonstrate a potential workflow and the relative simplicity of using machine learning to derive improved attrition insights from an imperfect dataset. \n",
    "\n",
    "\n",
    "\n",
    "**All Model Accuracies** \n",
    "\n",
    "    1. Logistic Regression:        89.1% \n",
    "    2. Extreme Gradient Boosting:  88.5% \n",
    "    3. Support Vector Machine:     88.0% \n",
    "    4. Deep Neural Net:            87.4%\n",
    "    5. Random Forest:              87.2% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme Gradient Boosting ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset into a dataframe\n",
    "attrition=pd.read_csv('ibm_employee_attrition_encoded.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 52 columns):\n",
      "Unnamed: 0                           1470 non-null int64\n",
      "Age                                  1470 non-null int64\n",
      "Attrition                            1470 non-null int64\n",
      "BusinessTravel                       1470 non-null int64\n",
      "DailyRate                            1470 non-null int64\n",
      "DistanceFromHome                     1470 non-null int64\n",
      "Education                            1470 non-null int64\n",
      "EmployeeCount                        1470 non-null int64\n",
      "EmployeeNumber                       1470 non-null int64\n",
      "EnvironmentSatisfaction              1470 non-null int64\n",
      "HourlyRate                           1470 non-null int64\n",
      "JobInvolvement                       1470 non-null int64\n",
      "JobLevel                             1470 non-null int64\n",
      "JobSatisfaction                      1470 non-null int64\n",
      "MonthlyIncome                        1470 non-null int64\n",
      "MonthlyRate                          1470 non-null int64\n",
      "NumCompaniesWorked                   1470 non-null int64\n",
      "OverTime                             1470 non-null int64\n",
      "PercentSalaryHike                    1470 non-null int64\n",
      "PerformanceRating                    1470 non-null int64\n",
      "RelationshipSatisfaction             1470 non-null int64\n",
      "StockOptionLevel                     1470 non-null int64\n",
      "TotalWorkingYears                    1470 non-null int64\n",
      "TrainingTimesLastYear                1470 non-null int64\n",
      "WorkLifeBalance                      1470 non-null int64\n",
      "YearsAtCompany                       1470 non-null int64\n",
      "YearsInCurrentRole                   1470 non-null int64\n",
      "YearsSinceLastPromotion              1470 non-null int64\n",
      "YearsWithCurrManager                 1470 non-null int64\n",
      "Department_Human Resources           1470 non-null int64\n",
      "Department_Research & Development    1470 non-null int64\n",
      "Department_Sales                     1470 non-null int64\n",
      "EducationField_Human Resources       1470 non-null int64\n",
      "EducationField_Life Sciences         1470 non-null int64\n",
      "EducationField_Marketing             1470 non-null int64\n",
      "EducationField_Medical               1470 non-null int64\n",
      "EducationField_Other                 1470 non-null int64\n",
      "EducationField_Technical Degree      1470 non-null int64\n",
      "Gender_Female                        1470 non-null int64\n",
      "Gender_Male                          1470 non-null int64\n",
      "JobRole_Healthcare Representative    1470 non-null int64\n",
      "JobRole_Human Resources              1470 non-null int64\n",
      "JobRole_Laboratory Technician        1470 non-null int64\n",
      "JobRole_Manager                      1470 non-null int64\n",
      "JobRole_Manufacturing Director       1470 non-null int64\n",
      "JobRole_Research Director            1470 non-null int64\n",
      "JobRole_Research Scientist           1470 non-null int64\n",
      "JobRole_Sales Executive              1470 non-null int64\n",
      "JobRole_Sales Representative         1470 non-null int64\n",
      "MaritalStatus_Divorced               1470 non-null int64\n",
      "MaritalStatus_Married                1470 non-null int64\n",
      "MaritalStatus_Single                 1470 non-null int64\n",
      "dtypes: int64(52)\n",
      "memory usage: 597.3 KB\n"
     ]
    }
   ],
   "source": [
    "# examine the dataset \n",
    "attrition.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the first few rows of the dataset \n",
    "# attrition.head() # commented out for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train test split in the data \n",
    "X = attrition.drop(columns=['Attrition'])\n",
    "y = attrition['Attrition']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
    "                                                    random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train test splits for our xgboost classifier to use \n",
    "xgd_train=xgb.DMatrix(data=X_train,label=y_train)\n",
    "xgd_test=xgb.DMatrix(data=X_test,label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classifier \n",
    "# tinker with params in this section to achieve potentially better results \n",
    "params = {\"objective\":\"binary:logistic\", \"max_depth\":4,\n",
    "          \"nthread\":5,\"learning_rate\":0.1,\"subsample\":0.2,\n",
    "          \"colsample_bytree\":0.3,\"n_estimators\":20,\"seed\":52}\n",
    "\n",
    "# Initialize the XGBClassifier: xg_cl\n",
    "xg_cl = xgb.XGBClassifier(params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost model accuracy: 0.888587\n"
     ]
    }
   ],
   "source": [
    "# Fit the classifier to the training set\n",
    "xg_cl.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_cl.predict(X_test)\n",
    "\n",
    "# Compute the accuracy: accuracy\n",
    "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
    "print(\"xgboost model accuracy: %f\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True         0   1\n",
      "Predicted         \n",
      "0          308  36\n",
      "1            5  19\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       313\n",
      "          1       0.79      0.35      0.48        55\n",
      "\n",
      "avg / total       0.88      0.89      0.87       368\n",
      "\n",
      "\n",
      " 0.8885869565217391\n"
     ]
    }
   ],
   "source": [
    "# printing more detailed model metrics \n",
    "model=xg_cl\n",
    "pred=model.predict(X_test)\n",
    "cm_df = pd.DataFrame(confusion_matrix(y_test, pred).T, index=model.classes_,\n",
    "                     columns=model.classes_)\n",
    "\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)\n",
    "print('\\n',classification_report(y_test, pred))\n",
    "print('\\n',model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our data into a dataframe \n",
    "attrition=pd.read_csv('ibm_employee_attrition_encoded.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the data \n",
    "# attrition.info() #remove the comment here to see all columns (same as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the first few rows of the dataset \n",
    "# attrition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train test split in the data \n",
    "X = attrition.drop(columns=['Attrition'])\n",
    "y = attrition['Attrition']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                test_size=0.25, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc Train: 0.835753, Acc test:0.850543\n",
      "Acc Train: 0.840290, Acc test:0.855978\n",
      "Acc Train: 0.842105, Acc test:0.853261\n",
      "Acc Train: 0.877495, Acc test:0.883152\n",
      "Acc Train: 0.881125, Acc test:0.894022\n",
      "Acc Train: 0.886570, Acc test:0.896739\n",
      "Acc Train: 0.884755, Acc test:0.894022\n",
      "Acc Train: 0.887477, Acc test:0.896739\n",
      "Acc Train: 0.887477, Acc test:0.899457\n",
      "Acc Train: 0.889292, Acc test:0.894022\n"
     ]
    }
   ],
   "source": [
    "# find a good c value to use in our regressor \n",
    "\n",
    "c_values = [0.001,0.005,0.01,0.05,0.1,0.5,1.0,5.0,10.0,50.0] #experiment with different values here \n",
    "prediction_err = []\n",
    "train_err = []\n",
    "\n",
    "for c_val in c_values:\n",
    "    clf = LogisticRegression(C=c_val,max_iter=10000,random_state=18)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score_train = clf.score(X_train, y_train)\n",
    "    score_test = clf.score(X_test,y_test)\n",
    "    train_err.append(1-score_train)\n",
    "    prediction_err.append(1-score_test)\n",
    "    #val_error.append(1-score_val) \n",
    "    print(\"Acc Train: %f, Acc test:%f\"%(score_train,score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=18, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create our logistic regressor \n",
    "# experiment with different C values, or run in a loop like above\n",
    "logreg = LogisticRegression(C=50,max_iter=1000,random_state=18) \n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True         0   1\n",
      "Predicted         \n",
      "0          305  31\n",
      "1            8  24\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       313\n",
      "          1       0.75      0.44      0.55        55\n",
      "\n",
      "avg / total       0.88      0.89      0.88       368\n",
      "\n",
      "\n",
      "Logistic Regression Model Accuracy: 0.8940217391304348\n"
     ]
    }
   ],
   "source": [
    "# get the accuracy of our model \n",
    "model=logreg\n",
    "pred=model.predict(X_test)\n",
    "cm_df = pd.DataFrame(confusion_matrix(y_test, pred).T,\n",
    "                     index=model.classes_,columns=model.classes_)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)\n",
    "print('\\n',classification_report(y_test, pred))\n",
    "print('\\nLogistic Regression Model Accuracy:',model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our data into a dataframe \n",
    "attrition=pd.read_csv('ibm_employee_attrition_encoded.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the data \n",
    "# attrition.info() #remove this comment to see all columns, same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the first few rows of the dataset \n",
    "# attrition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train/test split in the data \n",
    "X = attrition.drop(columns=['Attrition'])\n",
    "y = attrition['Attrition']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                test_size=0.25, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features=20, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=True, random_state=18, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building our random forest classifier \n",
    "model= RandomForestClassifier(max_depth=10,n_estimators=100,oob_score=True,\n",
    "                              min_samples_split=5,random_state=18,\n",
    "                              min_samples_leaf=2,criterion='gini',max_features=20)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True         0   1\n",
      "Predicted         \n",
      "0          309  41\n",
      "1            4  14\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93       313\n",
      "          1       0.78      0.25      0.38        55\n",
      "\n",
      "avg / total       0.87      0.88      0.85       368\n",
      "\n",
      "\n",
      "model accuracy: 0.8777173913043478\n"
     ]
    }
   ],
   "source": [
    "# Model performance\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "cm_df = pd.DataFrame(confusion_matrix(y_test, pred).T, index=model.classes_,columns=model.classes_)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)\n",
    "print('\\n',classification_report(y_test, pred))\n",
    "print('\\nmodel accuracy:',model.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our data into a dataframe \n",
    "\n",
    "attrition=pd.read_csv('ibm_employee_attrition_encoded.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the columns \n",
    "# attrition.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the first few rows of the dataframe \n",
    "# attrition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train/test split in the data\n",
    "X = attrition.drop(columns=['Attrition'])\n",
    "y = attrition['Attrition']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                            test_size=0.25, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc Train: 0.843920, Acc Test:0.877717\n",
      "Acc Train: 0.842105, Acc Test:0.866848\n",
      "Acc Train: 0.844828, Acc Test:0.880435\n",
      "Acc Train: 0.841198, Acc Test:0.880435\n"
     ]
    }
   ],
   "source": [
    "# find a good value for c and testing in a few svms\n",
    "c_values = [0.01,0.1,1.0,10.0]\n",
    "prediction_err = []\n",
    "train_err = []\n",
    "\n",
    "for c_val in c_values:\n",
    "    clf = svm.SVC(kernel='linear', C=c_val,random_state=18)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score_train = clf.score(X_train, y_train)\n",
    "    score_test = clf.score(X_test,y_test)\n",
    "    train_err.append(1-score_train)\n",
    "    prediction_err.append(1-score_test) \n",
    "    print(\"Acc Train: %f, Acc Test:%f\"%(score_train,score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True         0   1\n",
      "Predicted         \n",
      "0          309  40\n",
      "1            4  15\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.93       313\n",
      "          1       0.79      0.27      0.41        55\n",
      "\n",
      "avg / total       0.87      0.88      0.85       368\n",
      "\n",
      "0.8804347826086957\n"
     ]
    }
   ],
   "source": [
    "# implementing an svm model and getting some statistics \n",
    "# SVC stands for support vector classification\n",
    "    \n",
    "clf = svm.SVC(kernel='linear', C=1.0,random_state=18)\n",
    "clf.fit(X_train, y_train)\n",
    "model=clf\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "cm_df = pd.DataFrame(confusion_matrix(y_test, pred).T, index=model.classes_,\n",
    "                     columns=model.classes_)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)\n",
    "print(classification_report(y_test, pred))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Net ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages \n",
    "\n",
    "import numpy \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# neural net packages \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset into a dataframe\n",
    "\n",
    "attrition=pd.read_excel('ibm_employee_attrition.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the top of the dataset \n",
    "#pd.set_option('display.expand_frame_repr', False)\n",
    "#attrition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map attrition to 1's and 0's \n",
    "\n",
    "attrition_map = {'Yes': 1, 'No': 0}\n",
    "attrition['Attrition'] = attrition['Attrition'].map(attrition_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department',\n",
       "       'DistanceFromHome', 'Education', 'EducationField', 'EmployeeCount',\n",
       "       'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender', 'HourlyRate',\n",
       "       'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction',\n",
       "       'MaritalStatus', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n",
       "       'Over18', 'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
       "       'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel',\n",
       "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
       "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
       "       'YearsWithCurrManager'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view all our column names \n",
    "\n",
    "attrition.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some basic info on our data\n",
    "# attrition.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                          int64\n",
       "Attrition                    int64\n",
       "BusinessTravel              object\n",
       "DailyRate                    int64\n",
       "Department                  object\n",
       "DistanceFromHome             int64\n",
       "Education                    int64\n",
       "EducationField              object\n",
       "EmployeeCount                int64\n",
       "EmployeeNumber               int64\n",
       "EnvironmentSatisfaction      int64\n",
       "Gender                      object\n",
       "HourlyRate                   int64\n",
       "JobInvolvement               int64\n",
       "JobLevel                     int64\n",
       "JobRole                     object\n",
       "JobSatisfaction              int64\n",
       "MaritalStatus               object\n",
       "MonthlyIncome                int64\n",
       "MonthlyRate                  int64\n",
       "NumCompaniesWorked           int64\n",
       "Over18                      object\n",
       "OverTime                    object\n",
       "PercentSalaryHike            int64\n",
       "PerformanceRating            int64\n",
       "RelationshipSatisfaction     int64\n",
       "StandardHours                int64\n",
       "StockOptionLevel             int64\n",
       "TotalWorkingYears            int64\n",
       "TrainingTimesLastYear        int64\n",
       "WorkLifeBalance              int64\n",
       "YearsAtCompany               int64\n",
       "YearsInCurrentRole           int64\n",
       "YearsSinceLastPromotion      int64\n",
       "YearsWithCurrManager         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the types of each column so we can one hot encode categorical variables \n",
    "# we can see we have 9 columns that will need to be encoded \n",
    "\n",
    "attrition.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BusinessTravel    object\n",
       "Department        object\n",
       "EducationField    object\n",
       "Gender            object\n",
       "JobRole           object\n",
       "MaritalStatus     object\n",
       "Over18            object\n",
       "OverTime          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrition.dtypes[attrition.dtypes!='int64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the categorical columns of our df \n",
    "attrition_cat = attrition.select_dtypes(include=['object'])\n",
    "\n",
    "for column in attrition_cat:\n",
    "    dummy=pd.get_dummies(attrition_cat[column])\n",
    "    attrition = pd.concat([attrition,dummy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all the redundant columns \n",
    "attrition=attrition.drop(columns=['BusinessTravel','Department','EducationField',\n",
    "                                  'Gender','JobRole','MaritalStatus','Over18',\n",
    "                                   'OverTime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Attrition', 'DailyRate', 'DistanceFromHome', 'Education',\n",
       "       'EmployeeCount', 'EmployeeNumber', 'EnvironmentSatisfaction',\n",
       "       'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction',\n",
       "       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n",
       "       'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction',\n",
       "       'StandardHours', 'StockOptionLevel', 'TotalWorkingYears',\n",
       "       'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany',\n",
       "       'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager',\n",
       "       'Non-Travel', 'Travel_Frequently', 'Travel_Rarely', 'Human Resources',\n",
       "       'Research & Development', 'Sales', 'Human Resources', 'Life Sciences',\n",
       "       'Marketing', 'Medical', 'Other', 'Technical Degree', 'Female', 'Male',\n",
       "       'Healthcare Representative', 'Human Resources', 'Laboratory Technician',\n",
       "       'Manager', 'Manufacturing Director', 'Research Director',\n",
       "       'Research Scientist', 'Sales Executive', 'Sales Representative',\n",
       "       'Divorced', 'Married', 'Single', 'Y', 'No', 'Yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view updated columns\n",
    "attrition.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns to use for prediction in the neural network \n",
    "prediction_var= ['Age', 'DailyRate', 'DistanceFromHome', 'Education',\n",
    "       'EmployeeCount', 'EmployeeNumber', 'EnvironmentSatisfaction',\n",
    "       'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction',\n",
    "       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n",
    "       'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction',\n",
    "       'StandardHours', 'StockOptionLevel', 'TotalWorkingYears',\n",
    "       'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany',\n",
    "       'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager',\n",
    "       'Non-Travel', 'Travel_Frequently', 'Travel_Rarely', 'Human Resources',\n",
    "       'Research & Development', 'Sales', 'Human Resources', 'Life Sciences',\n",
    "       'Marketing', 'Medical', 'Other', 'Technical Degree', 'Female', 'Male',\n",
    "       'Healthcare Representative', 'Human Resources', 'Laboratory Technician',\n",
    "       'Manager', 'Manufacturing Director', 'Research Director',\n",
    "       'Research Scientist', 'Sales Executive', 'Sales Representative',\n",
    "       'Divorced', 'Married', 'Single', 'Y', 'No', 'Yes']\n",
    "\n",
    "X = attrition[prediction_var].values\n",
    "Y = attrition['Attrition'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1470, 61), (1470,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm the shape of our data is correct \n",
    "(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the columns of our dataset\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple neural net using a function\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=20, input_dim=61, \n",
    "                    kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.02))\n",
    "    model.add(Dense(units=10, input_dim=61))\n",
    "    model.add(Dropout(0.02))\n",
    "    model.add(Dense(units=5,input_dim=10))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # for those interesting in creating a sqd optimizer instead of 'adam'\n",
    "    #sgd = SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    # Compile model with the logarithmic loss function and Adam gradient optimizer.\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model using standardized dataset and 10 fold cross validation\n",
    "estimators = []\n",
    "#estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, \n",
    "                                  epochs=2000, batch_size=800, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.41%\n"
     ]
    }
   ],
   "source": [
    "# model accuracy \n",
    "print(\"Accuracy: %.2f%%\" % (results.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
